{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRe9kdgG03fa",
        "outputId": "f64b9dc1-e6fd-4695-d505-6262955390ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'creditcard.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Explore the dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Standardize the 'Amount' and 'Time' columns\n",
        "scaler = StandardScaler()\n",
        "data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "data['Time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))\n",
        "\n",
        "# Address class imbalance by upsampling the minority class\n",
        "fraud = data[data['Class'] == 1]\n",
        "legit = data[data['Class'] == 0]\n",
        "\n",
        "fraud_upsampled = resample(fraud,\n",
        "                           replace=True,  # sample with replacement\n",
        "                           n_samples=len(legit),  # match number in majority class\n",
        "                           random_state=42)  # reproducible results\n",
        "\n",
        "data_upsampled = pd.concat([legit, fraud_upsampled])\n",
        "\n",
        "# Shuffle the dataset\n",
        "data_upsampled = data_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = data_upsampled.drop('Class', axis=1)\n",
        "y = data_upsampled['Class']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3PpaI7y1Ijq",
        "outputId": "abe829fb-cd28-439f-8b9d-581b1a4fcbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CORdzgL41YDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "RpE1-LGJ1cR8",
        "outputId": "5c19e1a0-e928-4dfd-bcca-20960141b97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "evaluate_model(lr_model, X_test, y_test)\n",
        "\n",
        "print(\"\\nDecision Tree:\")\n",
        "evaluate_model(dt_model, X_test, y_test)\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "evaluate_model(rf_model, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSjJHdMO1esF",
        "outputId": "c40e0295-35f7-48f3-ea8a-c315f6954b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.9510753917310026\n",
            "Precision: 0.9763966558811977\n",
            "Recall: 0.9238678393827313\n",
            "F1 Score: 0.949406223289141\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95     57219\n",
            "           1       0.98      0.92      0.95     56507\n",
            "\n",
            "    accuracy                           0.95    113726\n",
            "   macro avg       0.95      0.95      0.95    113726\n",
            "weighted avg       0.95      0.95      0.95    113726\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.9997537942071294\n",
            "Precision: 0.9995047315822058\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9997523044532121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     57219\n",
            "           1       1.00      1.00      1.00     56507\n",
            "\n",
            "    accuracy                           1.00    113726\n",
            "   macro avg       1.00      1.00      1.00    113726\n",
            "weighted avg       1.00      1.00      1.00    113726\n",
            "\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.9999736208079067\n",
            "Precision: 0.9999469120509644\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9999734553208809\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     57219\n",
            "           1       1.00      1.00      1.00     56507\n",
            "\n",
            "    accuracy                           1.00    113726\n",
            "   macro avg       1.00      1.00      1.00    113726\n",
            "weighted avg       1.00      1.00      1.00    113726\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Task2.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1VDcEQoCJH4iGoRwRUXMmYdwec1J4bhU3\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'creditcard.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Explore the dataset\n",
        "print(data.head())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Standardize the 'Amount' and 'Time' columns\n",
        "scaler = StandardScaler()\n",
        "data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "data['Time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))\n",
        "\n",
        "# Address class imbalance by upsampling the minority class\n",
        "fraud = data[data['Class'] == 1]\n",
        "legit = data[data['Class'] == 0]\n",
        "\n",
        "fraud_upsampled = resample(fraud,\n",
        "                           replace=True,  # sample with replacement\n",
        "                           n_samples=len(legit),  # match number in majority class\n",
        "                           random_state=42)  # reproducible results\n",
        "\n",
        "data_upsampled = pd.concat([legit, fraud_upsampled])\n",
        "\n",
        "# Shuffle the dataset\n",
        "data_upsampled = data_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = data_upsampled.drop('Class', axis=1)\n",
        "y = data_upsampled['Class']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Decision Tree\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "evaluate_model(lr_model, X_test, y_test)\n",
        "\n",
        "print(\"\\nDecision Tree:\")\n",
        "evaluate_model(dt_model, X_test, y_test)\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "evaluate_model(rf_model, X_test, y_test)"
      ],
      "metadata": {
        "id": "ChpWYEYKVSbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002fc2b5-6a92-4ea7-caf8-e89df05395a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
            "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
            "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
            "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       1\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.996220869200084\n",
            "Precision: 0.9924433249370277\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9962073324905183\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      1.00      2399\n",
            "         1.0       0.99      1.00      1.00      2364\n",
            "\n",
            "    accuracy                           1.00      4763\n",
            "   macro avg       1.00      1.00      1.00      4763\n",
            "weighted avg       1.00      1.00      1.00      4763\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.9995800965777871\n",
            "Precision: 0.9991546914623838\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9995771670190275\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2399\n",
            "         1.0       1.00      1.00      1.00      2364\n",
            "\n",
            "    accuracy                           1.00      4763\n",
            "   macro avg       1.00      1.00      1.00      4763\n",
            "weighted avg       1.00      1.00      1.00      4763\n",
            "\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2399\n",
            "         1.0       1.00      1.00      1.00      2364\n",
            "\n",
            "    accuracy                           1.00      4763\n",
            "   macro avg       1.00      1.00      1.00      4763\n",
            "weighted avg       1.00      1.00      1.00      4763\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzvfMq_0iP70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}